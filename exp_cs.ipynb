{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee43cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from diffusers import StableDiffusionInpaintPipeline, AutoencoderKL\n",
    "import timm\n",
    "import lpips\n",
    "from helper import load_images_from_path, norm_imagenet, denorm_imagenet\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),\n",
    "    # transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    # normalize_img,\n",
    "])\n",
    "\n",
    "def load_img(path, transforms=None):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img = transforms(img).unsqueeze(0).to(device)\n",
    "    return img\n",
    "\n",
    "def norm_tensor(tensor):\n",
    "    t = tensor.clone().detach()\n",
    "    \n",
    "    min_val = t.min()\n",
    "    max_val = t.max()\n",
    "\n",
    "    tensor_norm = (tensor - min_val) / (max_val - min_val)\n",
    "\n",
    "    print(f\"Tensor normalized: min={tensor_norm.min()}, max={tensor_norm.max()}\")\n",
    "    \n",
    "    return tensor_norm, min_val, max_val\n",
    "\n",
    "def denorm_tensor(tensor, original_min=None, original_max=None):\n",
    "    t = tensor.clone().detach()\n",
    "\n",
    "    return t * (original_max - original_min) + original_min\n",
    "\n",
    "def create_random_mask(img_pt, num_masks=1, mask_percentage=0.1, max_attempts=100):\n",
    "    _, _, height, width = img_pt.shape\n",
    "    mask_area = int(height * width * mask_percentage)\n",
    "    masks = torch.zeros((num_masks, 1, height, width), dtype=img_pt.dtype)\n",
    "\n",
    "    if mask_percentage >= 0.999:\n",
    "        # Full mask for entire image\n",
    "        return torch.ones((num_masks, 1, height, width), dtype=img_pt.dtype).to(img_pt.device)\n",
    "\n",
    "    for ii in range(num_masks):\n",
    "        placed = False\n",
    "        attempts = 0\n",
    "        while not placed and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "\n",
    "            max_dim = int(mask_area ** 0.5)\n",
    "            mask_width = random.randint(1, max_dim)\n",
    "            mask_height = mask_area // mask_width\n",
    "\n",
    "            # Allow broader aspect ratios for larger masks\n",
    "            aspect_ratio = mask_width / mask_height if mask_height != 0 else 0\n",
    "            if 0.25 <= aspect_ratio <= 4:  # Looser ratio constraint\n",
    "                if mask_height <= height and mask_width <= width:\n",
    "                    x_start = random.randint(0, width - mask_width)\n",
    "                    y_start = random.randint(0, height - mask_height)\n",
    "                    overlap = False\n",
    "                    for jj in range(ii):\n",
    "                        if torch.sum(masks[jj, :, y_start:y_start + mask_height, x_start:x_start + mask_width]) > 0:\n",
    "                            overlap = True\n",
    "                            break\n",
    "                    if not overlap:\n",
    "                        masks[ii, :, y_start:y_start + mask_height, x_start:x_start + mask_width] = 1\n",
    "                        placed = True\n",
    "\n",
    "        if not placed:\n",
    "            # Fallback: just fill a central region if all attempts fail\n",
    "            print(f\"Warning: Failed to place mask {ii}, using fallback.\")\n",
    "            center_h = height // 2\n",
    "            center_w = width // 2\n",
    "            half_area = int((mask_area // 2) ** 0.5)\n",
    "            h_half = min(center_h, half_area)\n",
    "            w_half = min(center_w, half_area)\n",
    "            masks[ii, :, center_h - h_half:center_h + h_half, center_w - w_half:center_w + w_half] = 1\n",
    "\n",
    "    return masks.to(img_pt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    \"\"\"Hyperparameters and configuration settings for FreqMark.\"\"\"\n",
    "    def __init__(self):\n",
    "        # --- System & Paths ---\n",
    "        self.device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "        self.image_path = '/mnt/nas5/suhyeon/datasets/DIV2K_train_HR/0002.png'\n",
    "\n",
    "        # --- Model Configurations ---\n",
    "        self.vae_model_name = \"stabilityai/stable-diffusion-2-1\"\n",
    "        self.vae_subfolder = \"vae\"\n",
    "        self.dino_model_repo = 'facebookresearch/dinov2'\n",
    "        self.dino_model_name = 'dinov2_vits14'\n",
    "        \n",
    "        # --- Image Size Parameters ---\n",
    "        self.vae_image_size = 512\n",
    "        self.image_size = 384\n",
    "        self.transform = transforms.Compose([\n",
    "            # transforms.Resize(256),\n",
    "            # transforms.CenterCrop(224),\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        # --- FreqMark Core Parameters ---\n",
    "        self.message_bits = 2\n",
    "        self.feature_dim = 128\n",
    "        self.margin = 1.0\n",
    "        self.grid_size = 28\n",
    "        self.num_patches = self.grid_size*self.grid_size\n",
    "\n",
    "        # --- Optimization Parameters ---\n",
    "        self.lr = 2.0\n",
    "        self.steps = 400\n",
    "        self.lambda_p = 0.05\n",
    "        self.lambda_i = 0.25\n",
    "\n",
    "        # --- Robustness Parameters ---\n",
    "        self.eps1_std = 0.25 \n",
    "        self.eps2_std = 0.06\n",
    "        \n",
    "        # --- Demo/Evaluation Parameters ---\n",
    "        self.batch_size = 4\n",
    "        self.num_test_images = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf3a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psnr(a, b):\n",
    "    mse = F.mse_loss(a, b).item()\n",
    "    if mse == 0:\n",
    "        return 100.0\n",
    "    return 20 * torch.log10(1.0 / torch.sqrt(torch.tensor(mse)))\n",
    "\n",
    "def calculate_iou(pred_mask, gt_mask):\n",
    "    # Ensure masks are binary\n",
    "    # pred_mask_bin = (pred_mask < 0).float()\n",
    "    pred_mask_bin = torch.sigmoid(pred_mask)\n",
    "    pred_mask_bin = (pred_mask_bin > 0.65).float() # Thresholding at 0.65\n",
    "    gt_mask_bin = (gt_mask > 0).float() # Ground truth might not be 0/1\n",
    "\n",
    "    save_image(pred_mask, \"pred.png\")\n",
    "    save_image(pred_mask_bin, \"pred_bin.png\")\n",
    "    save_image(gt_mask_bin, \"gt.png\")\n",
    "    save_image(pred_mask_bin * gt_mask_bin, \"intersection.png\")\n",
    "    save_image(pred_mask_bin + gt_mask_bin, \"union.png\")\n",
    "\n",
    "    # Intersection and Union\n",
    "    intersection = (pred_mask_bin * gt_mask_bin).sum()\n",
    "    union = (pred_mask_bin + gt_mask_bin).sum() - intersection\n",
    "\n",
    "    iou = intersection / (union + 1e-6) # Add epsilon to avoid division by zero\n",
    "    return iou.item()\n",
    "\n",
    "def calculate_cosine_similarity_matrix(F_a, F_b):\n",
    "    # F_a, F_b: [B, C, H, W] 형태 가정\n",
    "    B, C, H, W = F_a.shape\n",
    "    \n",
    "    # \n",
    "    # 1. (B, C, H, W) -> (B, H, W, C) -> (B, H*W, C) 형태로 변환 (Patch Vector화)\n",
    "    F_a = F_a.permute(0, 2, 3, 1).reshape(B, H * W, C)\n",
    "    F_b = F_b.permute(0, 2, 3, 1).reshape(B, H * W, C)\n",
    "    \n",
    "    # 2. L2 정규화 (방향만 비교)\n",
    "    F_a_norm = F.normalize(F_a, p=2, dim=-1)\n",
    "    F_b_norm = F.normalize(F_b, p=2, dim=-1)\n",
    "    \n",
    "    # 3. 코사인 유사도 계산 (F_a와 F_b 간의 각 패치별 내적)\n",
    "    # 결과: [B, H*W] (패치별 코사인 유사도)\n",
    "    cosine_sim = (F_a_norm * F_b_norm).sum(dim=-1)\n",
    "    \n",
    "    return cosine_sim.mean().item(), cosine_sim.max().item(), cosine_sim.min().item()\n",
    "\n",
    "def generate_universal_vectors(args, feature_dim):\n",
    "    \"\"\"\n",
    "    어떤 Feature가 들어와도 DC 성분(크기)을 무시하고 \n",
    "    방향만 검출할 수 있는 Universal Vector 생성\n",
    "    \"\"\"\n",
    "    # 1. 랜덤 생성\n",
    "    vecs = torch.randn(1, feature_dim)\n",
    "    \n",
    "    # 2. [핵심] Zero-Mean Centering (평균 제거)\n",
    "    # 각 벡터(row)의 평균을 계산해서 뺌 -> 합이 0이 됨\n",
    "    vecs = vecs - vecs.mean(dim=1, keepdim=True)\n",
    "    \n",
    "    # 3. Sign Quantization (강건성 향상)\n",
    "    # 0인 경우를 방지하기 위해 아주 작은 noise 추가 후 sign\n",
    "    vecs = torch.sign(vecs + 1e-6)\n",
    "    \n",
    "    # 4. L2 Normalization\n",
    "    vecs = vecs / torch.norm(vecs, p=2, dim=1, keepdim=True)\n",
    "    \n",
    "    return vecs.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173a8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = \"/mnt/nas5/suhyeon/projects/freq-loc/secret_code/0002.png\"\n",
    "# img_path = \"/mnt/nas5/suhyeon/projects/freq-loc/secret_code/analysis_dist_wm_step400.png\"\n",
    "# img_path = \"/mnt/nas5/suhyeon/projects/freq-loc/baseline/20251119-105815/watermarked/0088.png\"\n",
    "seed = 45\n",
    "proportion_masked = 0.3\n",
    "trials = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288e47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]An error occurred while trying to fetch /mnt/nas5/suhyeon/caches/models--sd-legacy--stable-diffusion-inpainting/snapshots/8a4288a76071f7280aedbdb3253bdb9e9d5d84bb/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /mnt/nas5/suhyeon/caches/models--sd-legacy--stable-diffusion-inpainting/snapshots/8a4288a76071f7280aedbdb3253bdb9e9d5d84bb/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...:  14%|█▍        | 1/7 [00:00<00:01,  5.92it/s]An error occurred while trying to fetch /mnt/nas5/suhyeon/caches/models--sd-legacy--stable-diffusion-inpainting/snapshots/8a4288a76071f7280aedbdb3253bdb9e9d5d84bb/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /mnt/nas5/suhyeon/caches/models--sd-legacy--stable-diffusion-inpainting/snapshots/8a4288a76071f7280aedbdb3253bdb9e9d5d84bb/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor normalized: min=0.0, max=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor normalized: min=0.0, max=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor normalized: min=0.0, max=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor normalized: min=0.0, max=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor normalized: min=0.0, max=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      "✨ 마스크 영역별 코사인 유사도 분석 (평균)\n",
      "===========================================================================\n",
      "총 Trial 횟수: 5회\n",
      "\n",
      "## 1. Original Image Baseline (워터마킹 목표점)\n",
      "---------------------------------------------------------------------------\n",
      "| 영역 | 평균 Cos Sim | STD (변동성) |\n",
      "|:---|:---|:---|\n",
      "| 마스크 안쪽 (Inpaint Target) | -0.0168 | 0.0045 |\n",
      "| 마스크 바깥쪽 (Background) | -0.0203 | 0.0020 |\n",
      "\n",
      "## 2. Inpainted Image Result (Attack Effectiveness)\n",
      "---------------------------------------------------------------------------\n",
      "| 영역 | 평균 Cos Sim | Original 대비 변화량 | 진단 |\n",
      "|:---|:---|:---|:---|\n",
      "| 마스크 안쪽 (Attack Result) | -0.0097 | +0.0071 |\n",
      "| 마스크 바깥쪽 (Leakage Check) | -0.0162 | +0.0040 |\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "### 최종 진단: Localization 가능성\n",
      "❌ Localization 실패 (너무 강건함): Inpainting 공격이 워터마크를 제거하지 못하고 Cos Sim을 유지하고 있습니다.\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"sd-legacy/stable-diffusion-inpainting\",\n",
    "    # torch_dtype=torch.float16,\n",
    "    cache_dir='/mnt/nas5/suhyeon/caches'\n",
    ").to(device)\n",
    "\n",
    "args = Params()\n",
    "\n",
    "# secret_key = torch.load('./learned_directional_vector.pt')\n",
    "# freqmark.direction_vectors = torch.tensor(secret_key).to(args.device)\n",
    "# print(freqmark.direction_vectors)\n",
    "\n",
    "image_encoder = timm.create_model(\n",
    "    'convnext_small.dinov3_lvd1689m',  # 또는 ConvNeXt 변형 (예: dinov3_convnext_t)\n",
    "    pretrained=True,\n",
    "    features_only=True\n",
    ").to(device)\n",
    "image_encoder.eval()\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "generator = torch.Generator(device=device).manual_seed(seed)\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# watermarked = load_img(img_path, transforms=args.transform)\n",
    "original = load_img('/mnt/nas5/suhyeon/datasets/valAGE-Set/0088.png', transforms=val_transforms)\n",
    "\n",
    "# original = F.interpolate(original, size=(512, 512), mode=\"bilinear\", align_corners=False)\n",
    "# watermarked = F.interpolate(watermarked, size=(512, 512), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "psnrs = []\n",
    "ious = []\n",
    "logits = []\n",
    "\n",
    "orig_inside_list = []\n",
    "orig_outside_list = []\n",
    "inpaint_inside_list = []\n",
    "inpaint_outside_list = []\n",
    "\n",
    "epsilon = 1e-6\n",
    "# direction_vectors = torch.load('/mnt/nas5/suhyeon/projects/freq-loc/random_vec_univ.pt').to(args.device)\n",
    "direction_vectors = generate_universal_vectors(args, feature_dim=192)\n",
    "\n",
    "for _ in range(trials):\n",
    "    mask = create_random_mask(original, num_masks=1, mask_percentage=proportion_masked)\n",
    "\n",
    "    img_norm, min_norm, max_norm = norm_tensor(original)\n",
    "\n",
    "    # original = F.interpolate(original, size=(args.image_size, args.image_size), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    features = image_encoder(original)[0]\n",
    "    B, C, H, W = features.shape\n",
    "    features = features.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "    # B, H, W, C = features.shape\n",
    "    # features = features.view(B, H * W, C)\n",
    "    features_norm = features / (torch.norm(features, p=2, dim=-1, keepdim=True) + epsilon)\n",
    "    original_cs = torch.matmul(features_norm, direction_vectors.T)\n",
    "\n",
    "    # 마스크를 Feature Map 크기에 맞게 리사이즈 [B, 1, H, W]\n",
    "    mask_small = F.interpolate(mask, size=(H, W), mode='bilinear', align_corners=False).squeeze(1).bool()\n",
    "    \n",
    "    # 1. Original: Inside Mask (Inpainting Target Area)\n",
    "    # mask_small [B, H, W] -> [B, H*W]\n",
    "    cs_inside_orig = original_cs[mask_small.view(B, H*W)] \n",
    "    orig_inside_list.append(cs_inside_orig.mean().item())\n",
    "    \n",
    "    # 2. Original: Outside Mask (Background)\n",
    "    cs_outside_orig = original_cs[~mask_small.view(B, H*W)]\n",
    "    orig_outside_list.append(cs_outside_orig.mean().item())\n",
    "    \n",
    "    img_edit_pil = pipe(prompt=\"\", image=img_norm, mask_image=mask, generator=generator).images[0]\n",
    "    img_edit = to_tensor(img_edit_pil)\n",
    "    img_edit = img_edit.unsqueeze(0).to(device)\n",
    "    img_edit = F.interpolate(img_edit, size=(args.image_size, args.image_size), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    features = image_encoder(img_edit)[0]\n",
    "    B, C, H, W = features.shape\n",
    "    features = features.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "    # B, H, W, C = features.shape\n",
    "    # features = features.view(B, H * W, C)\n",
    "    features_norm = features / (torch.norm(features, p=2, dim=-1, keepdim=True) + epsilon)\n",
    "    inpaint_cs = torch.matmul(features_norm, direction_vectors.T)\n",
    "\n",
    "    # 3. Inpainted: Inside Mask (Attack Result Area)\n",
    "    cs_inside_inpaint = inpaint_cs[mask_small.view(B, H*W)]\n",
    "    inpaint_inside_list.append(cs_inside_inpaint.mean().item())\n",
    "    \n",
    "    # 4. Inpainted: Outside Mask (Background)\n",
    "    cs_outside_inpaint = inpaint_cs[~mask_small.view(B, H*W)]\n",
    "    inpaint_outside_list.append(cs_outside_inpaint.mean().item())\n",
    "\n",
    "    # img_edit = denorm_tensor(img_edit, min_norm, max_norm)  # [1, 3, H, W]\n",
    "\n",
    "    save_image(original, \"./exp_cs/original.png\")\n",
    "    save_image(img_edit, \"./exp_cs/inpainted.png\")\n",
    "\n",
    "def calculate_metrics(data_list):\n",
    "    if not data_list:\n",
    "        return 0.0, 0.0\n",
    "    return np.mean(data_list), np.std(data_list)\n",
    "\n",
    "avg_orig_inside, std_orig_inside = calculate_metrics(orig_inside_list)\n",
    "avg_orig_outside, std_orig_outside = calculate_metrics(orig_outside_list)\n",
    "avg_inpaint_inside, std_inpaint_inside = calculate_metrics(inpaint_inside_list)\n",
    "avg_inpaint_outside, std_inpaint_outside = calculate_metrics(inpaint_outside_list)\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"✨ 마스크 영역별 코사인 유사도 분석 (평균)\")\n",
    "print(\"=\"*75)\n",
    "print(f\"총 Trial 횟수: {trials}회\")\n",
    "\n",
    "print(\"\\n## 1. Original Image Baseline (워터마킹 목표점)\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"| 영역 | 평균 Cos Sim | STD (변동성) |\")\n",
    "print(f\"|:---|:---|:---|\")\n",
    "print(f\"| 마스크 안쪽 (Inpaint Target) | {avg_orig_inside:.4f} | {std_orig_inside:.4f} |\")\n",
    "print(f\"| 마스크 바깥쪽 (Background) | {avg_orig_outside:.4f} | {std_orig_outside:.4f} |\")\n",
    "\n",
    "print(\"\\n## 2. Inpainted Image Result (Attack Effectiveness)\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"| 영역 | 평균 Cos Sim | Original 대비 변화량 | 진단 |\")\n",
    "print(f\"|:---|:---|:---|:---|\")\n",
    "print(f\"| 마스크 안쪽 (Attack Result) | {avg_inpaint_inside:.4f} | {(avg_inpaint_inside - avg_orig_inside):+.4f} |\")\n",
    "print(f\"| 마스크 바깥쪽 (Leakage Check) | {avg_inpaint_outside:.4f} | {(avg_inpaint_outside - avg_orig_outside):+.4f} |\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "# 최종 진단: Localization 성공 여부 판단\n",
    "diff_inside = avg_inpaint_inside - avg_orig_inside\n",
    "diff_outside = avg_inpaint_outside - avg_orig_outside\n",
    "\n",
    "print(\"\\n### 최종 진단: Localization 가능성\")\n",
    "if diff_inside < -0.05 and abs(diff_outside) < 0.01:\n",
    "    print(f\"✅ Localization 성공 가능성 높음: 마스크 안쪽에서만 Cos Sim이 크게 하락({diff_inside:.4f})하여 공격 감지에 적합합니다.\")\n",
    "elif abs(diff_inside) < 0.01:\n",
    "    print(f\"❌ Localization 실패 (너무 강건함): Inpainting 공격이 워터마크를 제거하지 못하고 Cos Sim을 유지하고 있습니다.\")\n",
    "elif abs(diff_inside) > 0.05 and abs(diff_outside) > 0.05:\n",
    "    print(f\"⚠️ 실패 (전역 변화/Leakage): 마스크 안팎 모두 Cos Sim이 크게 변하여, Inpainting이 전역적인 특징 변화를 유발하고 있습니다.\")\n",
    "\n",
    "print(\"=\"*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc058300",
   "metadata": {},
   "source": [
    "layer [1]\n",
    "===========================================================================\n",
    "✨ 마스크 영역별 코사인 유사도 분석 (평균)\n",
    "===========================================================================\n",
    "총 Trial 횟수: 5회\n",
    "\n",
    "1. Original Image Baseline (워터마킹 목표점)\n",
    "---------------------------------------------------------------------------\n",
    "| 영역 | 평균 Cos Sim | STD (변동성) |\n",
    "|:---|:---|:---|\n",
    "| 마스크 안쪽 (Inpaint Target) | -0.0168 | 0.0045 |\n",
    "| 마스크 바깥쪽 (Background) | -0.0203 | 0.0020 |\n",
    "\n",
    "2. Inpainted Image Result (Attack Effectiveness)\n",
    "---------------------------------------------------------------------------\n",
    "| 영역 | 평균 Cos Sim | Original 대비 변화량 | 진단 |\n",
    "|:---|:---|:---|:---|\n",
    "| 마스크 안쪽 (Attack Result) | -0.0097 | +0.0071 |\n",
    "| 마스크 바깥쪽 (Leakage Check) | -0.0162 | +0.0040 |\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "최종 진단: Localization 가능성\n",
    "❌ Localization 실패 (너무 강건함): Inpainting 공격이 워터마크를 제거하지 못하고 Cos Sim을 유지하고 있습니다.\n",
    "==========================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d08685",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d61bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stableguard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
